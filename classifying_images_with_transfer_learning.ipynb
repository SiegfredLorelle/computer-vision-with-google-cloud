{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Images with Transfer Learning\n",
    "\n",
    "## Introduction\n",
    "In this notebook, you learn how to build a neural network to classify the tf-flowers (5 flowers) dataset by using a pre-trained image embedding.You load a pre-trained model which is trained on very large, general-purpose datasets and transfer that knowledge to the actual dataset that you want to classify. This means you use a pre-trained model instead of the Flattened layer as your first layer.\n",
    "\n",
    "## Learning objectives\n",
    "\n",
    "* Understand how to set up preprocessing in order to _convert image type and resize the image to the desired size._\n",
    "\n",
    "* Understand how to implement transfer learning with MobileNet.\n",
    "\n",
    "Each learning objective will correspond to a __#TODO__ in the student lab notebook -- try to complete this notebook first and then review the [solution notebook](../solutions/classifying_images_with_transfer_learning.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ugGJcxKAwhc2",
    "outputId": "8e946159-46cf-4aba-f53e-622e9ea8adee",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.5\n"
     ]
    }
   ],
   "source": [
    "# Import and print the installed version of TensorFlow\n",
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "LKXV5oRmkSTK",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def training_plot(metrics, history):\n",
    "  f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
    "  for idx, metric in enumerate(metrics):\n",
    "    ax[idx].plot(history.history[metric], ls='dashed')\n",
    "    ax[idx].set_xlabel(\"Epochs\")\n",
    "    ax[idx].set_ylabel(metric)\n",
    "    ax[idx].plot(history.history['val_' + metric]);\n",
    "    ax[idx].legend([metric, 'val_' + metric])\n",
    "\n",
    "# Call model.predict() on a few images in the evaluation dataset\n",
    "def plot_predictions(model, filename):\n",
    "  f, ax = plt.subplots(3, 5, figsize=(25,15))\n",
    "  dataset = (tf.data.TextLineDataset(filename).\n",
    "      map(decode_csv))\n",
    "  for idx, (img, label) in enumerate(dataset.take(15)):\n",
    "    ax[idx//5, idx%5].imshow((img.numpy()));\n",
    "    batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "    batch_pred = model.predict(batch_image)\n",
    "    pred = batch_pred[0]\n",
    "    label = CLASS_NAMES[label.numpy()]\n",
    "    pred_label_index = tf.math.argmax(pred).numpy()\n",
    "    pred_label = CLASS_NAMES[pred_label_index]\n",
    "    prob = pred[pred_label_index]\n",
    "    ax[idx//5, idx%5].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))\n",
    "    ax[idx//5, idx%5].axis('off')\n",
    "\n",
    "def show_trained_weights(model):\n",
    "  # CLASS_NAMES is ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "  LAYER = 1 # Layer 0 flattens the image, layer=1 is the first dense layer\n",
    "  WEIGHT_TYPE = 0 # 0 for weight, 1 for bias\n",
    "\n",
    "  f, ax = plt.subplots(1, 5, figsize=(15,15))\n",
    "  for flower in range(len(CLASS_NAMES)):\n",
    "    weights = model.layers[LAYER].get_weights()[WEIGHT_TYPE][:, flower]\n",
    "    min_wt = tf.math.reduce_min(weights).numpy()\n",
    "    max_wt = tf.math.reduce_max(weights).numpy()\n",
    "    flower_name = CLASS_NAMES[flower]\n",
    "    print(\"Scaling weights for {} in {} to {}\".format(\n",
    "        flower_name, min_wt, max_wt))\n",
    "    weights = (weights - min_wt)/(max_wt - min_wt)\n",
    "    ax[flower].imshow(weights.reshape(IMG_HEIGHT, IMG_WIDTH, 3));\n",
    "    ax[flower].set_title(flower_name);\n",
    "    ax[flower].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ATwrq3yQXCZ3",
    "outputId": "9836d417-81ff-4c86-839f-8cba6cbbbe17",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the available classes: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "# The import statement combines two operations; it searches for the named module, then it binds the results of that search\n",
    "# to a name in the local scope.\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "def read_and_decode(filename, reshape_dims):\n",
    "  # Read the file\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Convert the compressed string to a 3D uint8 tensor.\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32) # TODO 1: Your code goes here.\n",
    "  # Resize the image to the desired size.\n",
    "  return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "CLASS_NAMES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "print(\"These are the available classes:\", CLASS_NAMES)\n",
    "\n",
    "# the label is the index into CLASS_NAMES array\n",
    "def decode_csv(csv_row):\n",
    "  record_defaults = [\"path\", \"flower\"]\n",
    "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71kBPOGuSj95"
   },
   "source": [
    "## Transfer Learning with MobileNet\n",
    "\n",
    "Pre-trained models are models that are trained on large datasets and made available to be used as a way to create embeddings. For example, the [MobileNet model](https://ai.googleblog.com/2017/06/mobilenets-open-source-models-for.html) is a model with 1-4 million parameters that was trained on the [ImageNet (ILSVRC) dataset](http://www.image-net.org/challenges/LSVRC/) which consists of millions of images corresponding to hundreds of categories that were scraped from the web. The resulting embedding therefore has the ability to efficiently compress the information found in a wide variety of images. As long as the images you want to classify are similar in nature to the ones that MobileNet was trained on, the embeddings from MobileNet should give a great pre-trained embedding that you can use as a starting point to train a model on your smaller tf-flowers (5 flowers) dataset.\n",
    "A pre-trained MobileNet is available on TensorFlow Hub and you can easily load it as a Keras layer by passing in the URL to the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "f26lxDv5Srao",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import os\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "# parameterize to the values in the previous cell\n",
    "def train_and_evaluate(batch_size = 32,\n",
    "                       lrate = 0.001,\n",
    "                       l1 = 0.,\n",
    "                       l2 = 0.,\n",
    "                       num_hidden = 16):\n",
    "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "\n",
    "  train_dataset = (tf.data.TextLineDataset(\n",
    "      \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv\").\n",
    "      map(decode_csv)).batch(batch_size)\n",
    "\n",
    "  eval_dataset = (tf.data.TextLineDataset(\n",
    "      \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/eval_set.csv\").\n",
    "      map(decode_csv)).batch(32) # this doesn't matter\n",
    "\n",
    "  layers = [\n",
    "      hub.KerasLayer(\n",
    "          \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "          input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "          trainable=False,\n",
    "          name='mobilenet_embedding'),\n",
    "      tf.keras.layers.Dense(num_hidden,\n",
    "                            kernel_regularizer=regularizer, \n",
    "                            activation='relu',\n",
    "                            name='dense_hidden'),\n",
    "      tf.keras.layers.Dense(len(CLASS_NAMES), \n",
    "                            kernel_regularizer=regularizer,\n",
    "                            activation='softmax',\n",
    "                            name='flower_prob')\n",
    "  ]\n",
    "\n",
    "  # Group a linear stack of layers into a tf.keras.Model\n",
    "  model = tf.keras.Sequential(layers, name='flower_classification') # TODO 2: Your code goes here\n",
    "\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "  print(model.summary())\n",
    "  history = model.fit(train_dataset, validation_data=eval_dataset, epochs=5)\n",
    "  training_plot(['loss', 'accuracy'], history)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 929
    },
    "id": "jlxxxpeaT6ea",
    "outputId": "ad4f09e8-bc33-4c92-dc47-5fc73ec12f9c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 04:41:11.683640: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2024-06-24 04:41:11.683681: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-06-24 04:41:11.683711: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-20240624-123057): /proc/driver/nvidia/version does not exist\n",
      "2024-06-24 04:41:11.688842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"flower_classification\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenet_embedding (KerasLa (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "dense_hidden (Dense)         (None, 16)                20496     \n",
      "_________________________________________________________________\n",
      "flower_prob (Dense)          (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 2,278,565\n",
      "Trainable params: 20,581\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 04:41:14.262195: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104/104 [==============================] - 107s 994ms/step - loss: 0.6830 - accuracy: 0.7512 - val_loss: 0.3892 - val_accuracy: 0.8622\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 104s 989ms/step - loss: 0.2996 - accuracy: 0.9018 - val_loss: 0.3345 - val_accuracy: 0.8865\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 105s 997ms/step - loss: 0.2167 - accuracy: 0.9327 - val_loss: 0.3220 - val_accuracy: 0.8838\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 103s 986ms/step - loss: 0.1640 - accuracy: 0.9573 - val_loss: 0.3215 - val_accuracy: 0.8838\n",
      "Epoch 5/5\n",
      " 38/104 [=========>....................] - ETA: 58s - loss: 0.1212 - accuracy: 0.9704"
     ]
    }
   ],
   "source": [
    "model = train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "HEh_vh0vvnNd",
    "outputId": "e43ebba2-fe2b-4a53-8b94-32598c021498"
   },
   "outputs": [],
   "source": [
    "plot_predictions(model, \"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/eval_set.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5UOm2etrwYCs"
   ],
   "name": "03a_transfer_learning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/tf2-gpu.2-6:m120"
  },
  "kernelspec": {
   "display_name": "Python 3 (Local)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
